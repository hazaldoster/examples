{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Building a YouTube Video Chat AI with Hyperbrowser and OpenAI\n",
                "\n",
                "In this cookbook, we'll build a powerful YouTube Video Analyst that can automatically extract transcripts from any YouTube video and allow you to have interactive conversations about the content. This approach combines:\n",
                "\n",
                "- **Hyperbrowser** for accessing YouTube and extracting transcripts in a reliable way\n",
                "- **Playwright** for browser automation and interaction with YouTube's interface\n",
                "- **OpenAI's language models** for understanding and responding to questions about the video content\n",
                "\n",
                "By the end of this cookbook, you'll have a reusable tool that can help you extract insights from any YouTube video without having to watch it entirely!"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Prerequisites\n",
                "\n",
                "Before starting, make sure you have:\n",
                "\n",
                "1. A Hyperbrowser API key (sign up at [hyperbrowser.ai](https://hyperbrowser.ai) if you don't have one, it's free)\n",
                "2. An OpenAI API key\n",
                "3. Python 3.9+ installed\n",
                "\n",
                "Both API keys should be stored in a `.env` file in the same directory as this notebook with the following format:\n",
                "\n",
                "```\n",
                "HYPERBROWSER_API_KEY=your_hyperbrowser_key_here\n",
                "OPENAI_API_KEY=your_openai_key_here\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 1: Set up imports and initialize clients\n",
                "\n",
                "First, we'll import the necessary libraries and initialize our clients. We're using Hyperbrowser to access YouTube, Playwright for browser automation, and OpenAI for natural language processing."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import asyncio\n",
                "from IPython.display import display, Markdown\n",
                "from playwright.async_api import async_playwright, Page\n",
                "from openai import AsyncOpenAI\n",
                "from openai.types.chat import ChatCompletionMessageParam\n",
                "from dotenv import load_dotenv\n",
                "\n",
                "# Load environment variables\n",
                "load_dotenv()\n",
                "\n",
                "from hyperbrowser.client.async_client import AsyncHyperbrowser\n",
                "from hyperbrowser.models.session import CreateSessionParams\n",
                "from openai.types.chat.chat_completion import ChatCompletion\n",
                "\n",
                "# Initialize OpenAI client\n",
                "client = AsyncOpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 2: Create transcript extraction functions\n",
                "\n",
                "Here we'll define functions to extract and format the transcript from a YouTube video. The process involves:\n",
                "\n",
                "1. Navigating to the YouTube video page\n",
                "2. Finding and clicking the \"Show transcript\" button\n",
                "3. Extracting the transcript text from the page\n",
                "4. Formatting the transcript for easy reading and analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [],
            "source": [
                "async def get_youtube_transcript(page: Page, url: str):\n",
                "    \"\"\"Get the transcript of a YouTube video directly from the page using Playwright.\"\"\"\n",
                "    try:\n",
                "        # Brief delay to ensure the video is loaded\n",
                "        await asyncio.sleep(0.5)\n",
                "        # Pause the video\n",
                "        await page.keyboard.press(\"k\")\n",
                "\n",
                "        # Wait for the video player to load\n",
                "        description_selector = await page.wait_for_selector(\n",
                "            \"div#description\", state=\"visible\"\n",
                "        )\n",
                "        if description_selector is None:\n",
                "            return None\n",
                "        await description_selector.click()\n",
                "\n",
                "        # Click the \"Show transcript\" button\n",
                "        transcript_show_more_selector = await page.wait_for_selector(\n",
                "            'button[aria-label=\"Show transcript\"]', state=\"visible\"\n",
                "        )\n",
                "        if transcript_show_more_selector is None:\n",
                "            return None\n",
                "        await transcript_show_more_selector.click()\n",
                "\n",
                "        # Wait for the transcript to be visible\n",
                "        transcript_display_selector = await page.wait_for_selector(\n",
                "            \"ytd-transcript-segment-list-renderer\", state=\"visible\"\n",
                "        )\n",
                "        if transcript_display_selector is None:\n",
                "            return None\n",
                "\n",
                "        # Extract the transcript segments\n",
                "        transcript_segments: list[dict] = await transcript_display_selector.evaluate(\n",
                "            \"\"\"()=>(\n",
                "                    [...document\n",
                "                        .querySelector(\"ytd-transcript-segment-list-renderer\")\n",
                "                        .querySelector(\"div#segments-container\")\n",
                "                        .querySelectorAll(\"ytd-transcript-segment-renderer\")\n",
                "                    ].map(e=>({\n",
                "                        text: e.querySelector(\"yt-formatted-string\").innerText\n",
                "                        })\n",
                "                    )\n",
                "                )\"\"\"\n",
                "        )\n",
                "\n",
                "        # Return the transcript data\n",
                "        if transcript_segments and isinstance(transcript_segments, list):\n",
                "            return transcript_segments\n",
                "        else:\n",
                "            print(\"Failed to extract transcript segments\")\n",
                "            return None\n",
                "\n",
                "    except Exception as e:\n",
                "        print(f\"Error getting transcript: {str(e)}\")\n",
                "        return None\n",
                "\n",
                "\n",
                "def format_transcript(transcript_segments):\n",
                "    \"\"\"Format transcript segments into a readable string.\"\"\"\n",
                "    if not transcript_segments:\n",
                "        return \"\"\n",
                "\n",
                "    formatted_text = \"\"\n",
                "    for segment in transcript_segments:\n",
                "        formatted_text += f\"{segment['text']} \"\n",
                "\n",
                "    return formatted_text.strip()\n",
                "\n",
                "async def get_transcript(url: str):\n",
                "    async with async_playwright() as playwright:\n",
                "        client = AsyncHyperbrowser(\n",
                "            api_key=os.getenv(\"HYPERBROWSER_API_KEY\"),\n",
                "        )\n",
                "        session = await client.sessions.create(CreateSessionParams(use_proxy=True))\n",
                "        browser_url = session.ws_endpoint\n",
                "        if browser_url is None:\n",
                "            raise Exception(\"Browser URL not found\")\n",
                "\n",
                "        browser = await playwright.chromium.connect_over_cdp(browser_url)\n",
                "        context = await browser.new_context()\n",
                "        page = await context.new_page()\n",
                "\n",
                "        await page.goto(url)\n",
                "\n",
                "        # Get video transcript directly from YouTube page\n",
                "        transcript_segments = await get_youtube_transcript(page, url)\n",
                "        return transcript_segments"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 3: Implement the chat functionality\n",
                "\n",
                "Now we'll create a function that allows us to chat with the video transcript. This function:\n",
                "\n",
                "1. Takes the transcript segments, a user prompt, and optional chat history\n",
                "2. Formats a message for the OpenAI API with system instructions\n",
                "3. Sends the message to OpenAI and gets a response\n",
                "4. Maintains conversation context for follow-up questions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [],
            "source": [
                "async def chat_with_transcript(\n",
                "    transcript_segments, prompt, chat_history=None,\n",
                "):\n",
                "    \"\"\"Use OpenAI to chat with the transcript content.\"\"\"\n",
                "    try:\n",
                "        # Format the transcript for the prompt\n",
                "        formatted_transcript = format_transcript(transcript_segments)\n",
                "\n",
                "        # Start with system message\n",
                "        messages: list[ChatCompletionMessageParam] = [\n",
                "            {\n",
                "                \"role\": \"system\",\n",
                "                \"content\": f\"You are an AI assistant that helps users understand the content of a YouTube video. Here is the transcript of the video:\\n\\n{formatted_transcript}\\n\\nAnswer questions based only on the content of this transcript. If you don't know the answer, preface your response by saying that you are inferring the answer based on your training data, and not the transcript.\",\n",
                "            },\n",
                "        ]\n",
                "\n",
                "        # Add chat history to provide context\n",
                "        if chat_history:\n",
                "            for prev_query, prev_response in chat_history:\n",
                "                messages.append({\"role\": \"user\", \"content\": prev_query})\n",
                "                messages.append({\"role\": \"assistant\", \"content\": prev_response})\n",
                "\n",
                "        # Add current user query\n",
                "        messages.append({\"role\": \"user\", \"content\": prompt})\n",
                "\n",
                "        # Call OpenAI API\n",
                "        response: ChatCompletion = await client.chat.completions.create(\n",
                "            model=\"gpt-4o-mini\", messages=messages, temperature=0.7, max_tokens=500\n",
                "        )\n",
                "\n",
                "        return response.choices[0].message.content\n",
                "    except Exception as e:\n",
                "        return f\"Error: {str(e)}\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 4: Extract the transcript from the YouTube video\n",
                "\n",
                "Let's run our transcript extraction function on the YouTube video URL we specified earlier. This will open a browser session through Hyperbrowser, navigate to the video, and extract the transcript."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Set your YouTube URL here\n",
                "youtube_url = \"https://www.youtube.com/watch?v=dQw4w9WgXcQ\"  # Replace with your video URL\n",
                "\n",
                "transcript_segments = await get_transcript(youtube_url)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 5: Ask questions about the video content\n",
                "\n",
                "Now that we have the transcript, let's ask some questions about the video! We'll start by initializing a chat history to keep track of our conversation, then ask our first question."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/markdown": [
                            "**Question:** What is the main topic of this video?"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "**Answer:** The main topic of the video is the song \"Never Gonna Give You Up\" by Rick Astley. The lyrics express themes of commitment, loyalty, and reassurance in a romantic relationship."
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# Initialize chat history\n",
                "chat_history = []\n",
                "\n",
                "# Ask your first question here\n",
                "question = \"What is the main topic of this video?\"\n",
                "\n",
                "display(Markdown(f\"**Question:** {question}\"))\n",
                "\n",
                "if transcript_segments:\n",
                "    response = await chat_with_transcript(transcript_segments, question, chat_history)\n",
                "    display(Markdown(f\"**Answer:** {response}\"))\n",
                "\n",
                "    # Add to chat history\n",
                "    chat_history.append((question, response))\n",
                "else:\n",
                "    display(\n",
                "        Markdown(\n",
                "            \"Cannot answer questions without a transcript. Please check the YouTube URL.\"\n",
                "        )\n",
                "    )"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 6: Ask follow-up questions\n",
                "\n",
                "Now let's ask a follow-up question to demonstrate how the conversation history helps provide context for subsequent answers."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/markdown": [
                            "**Question:** What are the key points mentioned?"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "**Answer:** The key points mentioned in the transcript include:\n",
                            "\n",
                            "1. **Commitment and Loyalty**: The singer emphasizes that he will never give up, let down, or desert the person he is addressing.\n",
                            "2. **Emotional Connection**: There is a recognition of a deep emotional bond, as both individuals have known each other for a long time and understand each other's feelings.\n",
                            "3. **Reassurance**: The singer wants to convey how he feels and assures the other person that he will not hurt them or say goodbye.\n",
                            "4. **Acknowledgment of Feelings**: The lyrics suggest that both individuals are aware of their feelings but may be hesitant to express them. \n",
                            "\n",
                            "Overall, the song conveys a message of unwavering support and love."
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# Ask another question (copy this cell for more questions)\n",
                "question = \"What are the key points mentioned?\"\n",
                "\n",
                "display(Markdown(f\"**Question:** {question}\"))\n",
                "\n",
                "if transcript_segments:\n",
                "    response = await chat_with_transcript(transcript_segments, question, chat_history)\n",
                "    display(Markdown(f\"**Answer:** {response}\"))\n",
                "\n",
                "    # Add to chat history\n",
                "    chat_history.append((question, response))\n",
                "else:\n",
                "    display(\n",
                "        Markdown(\n",
                "            \"Cannot answer questions without a transcript. Please check the YouTube URL.\"\n",
                "        )\n",
                "    )"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Conclusion\n",
                "\n",
                "Congratulations! You've built a YouTube Video AI Analyst that can:\n",
                "\n",
                "1. Automatically extract transcripts from any YouTube video\n",
                "2. Answer questions about the video content\n",
                "3. Maintain conversation context for natural follow-up questions\n",
                "4. Save you time by avoiding watching entire videos when you only need specific information\n",
                "\n",
                "This powerful tool combines the capabilities of Hyperbrowser for reliable browser automation, Playwright for YouTube interaction, and OpenAI for intelligent question answering.\n",
                "\n",
                "### Next Steps\n",
                "\n",
                "To take this project further, you might consider:\n",
                "- Adding support for video timestamp extraction to only extract specific parts of the video\n",
                "- Implementing automatic video summarization to get a quick overview of longer videos\n",
                "- Creating a user interface for easier interaction\n",
                "- Extracting and analyzing comments to understand viewer reactions, and correlating them to timestamps.\n",
                "\n",
                "Happy analyzing! ðŸŽ¬"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Relevant Links\n",
                "- [Hyperbrowser](https://hyperbrowser.ai)\n",
                "- [Playwright Documentation](https://playwright.dev/)\n",
                "- [OpenAI API Documentation](https://platform.openai.com/docs/introduction)\n",
                "- [YouTube Data API](https://developers.google.com/youtube/v3) (an alternative approach)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
